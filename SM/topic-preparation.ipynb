{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import DataFrameWriter\n",
    "import pandas as pd\n",
    "\n",
    "db = \"sm\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sdf = spark.sql(\"SELECT status_id, textTranslated AS text FROM \" + db + \".twitter\")\n",
    "#tweets_sdf = spark.sql(\"SELECT status_id, text FROM \" + db + \".twitter WHERE lang = 'en'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\", minTokenLength=4, \n",
    "                                toLowercase=True)\n",
    "tokenized_sdf = regexTokenizer.transform(tweets_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filtered_words_sdf = remover.transform(tokenized_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=100, minDF=10.0)\n",
    "cvmodel = cv.fit(filtered_words_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_local = pd.DataFrame(cvmodel.vocabulary, columns = [\"word\"])\n",
    "vocabulary_local[\"word_id\"] = vocabulary_local.index\n",
    "vocabulary_sdf = spark.createDataFrame(vocabulary_local)\n",
    "vocabulary_sdf.head()\n",
    "vocabulary_sdf.createOrReplaceTempView(\"vocab_v\")\n",
    "spark.sql(\"CREATE TABLE \" + db + \".vocab AS SELECT * FROM vocab_v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>islam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>immigration</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muslim</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>migration</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allah</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quran</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trump</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ramadan</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>muslims</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>brexit</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>people</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>daca</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>religion</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>islamic</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>immigrants</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>islamophobia</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>muhammad</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>like</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>world</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>isis</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>border</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>women</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>life</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stopbrexit</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>canada</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>finalsay</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tcot</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>news</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>know</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>children</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>years</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>pjnet</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>truth</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>state</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mexico</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>year</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>first</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>never</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>syria</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>judaism</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>stop</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>every</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>terrorism</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>said</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>watch</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>also</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>immigrant</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>take</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>iran</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>sharia</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>family</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>london</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>find</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>germany</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>australia</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>must</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>laws</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>book</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>saudiarabia</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  word_id\n",
       "0          https        0\n",
       "1          islam        1\n",
       "2    immigration        2\n",
       "3         muslim        3\n",
       "4      migration        4\n",
       "5          allah        5\n",
       "6          quran        6\n",
       "7          trump        7\n",
       "8        ramadan        8\n",
       "9        muslims        9\n",
       "10        brexit       10\n",
       "11        people       11\n",
       "12          daca       12\n",
       "13      religion       13\n",
       "14       islamic       14\n",
       "15    immigrants       15\n",
       "16  islamophobia       16\n",
       "17      muhammad       17\n",
       "18          like       18\n",
       "19         world       19\n",
       "20          isis       20\n",
       "21        border       21\n",
       "22         women       22\n",
       "23          life       23\n",
       "24    stopbrexit       24\n",
       "25        canada       25\n",
       "26      finalsay       26\n",
       "27          tcot       27\n",
       "28          news       28\n",
       "29          know       29\n",
       "..           ...      ...\n",
       "70      children       70\n",
       "71         years       71\n",
       "72         pjnet       72\n",
       "73         truth       73\n",
       "74         state       74\n",
       "75        mexico       75\n",
       "76          year       76\n",
       "77         first       77\n",
       "78         never       78\n",
       "79         syria       79\n",
       "80       judaism       80\n",
       "81          stop       81\n",
       "82         every       82\n",
       "83     terrorism       83\n",
       "84          said       84\n",
       "85         watch       85\n",
       "86          also       86\n",
       "87     immigrant       87\n",
       "88          take       88\n",
       "89          iran       89\n",
       "90        sharia       90\n",
       "91        family       91\n",
       "92        london       92\n",
       "93          find       93\n",
       "94       germany       94\n",
       "95     australia       95\n",
       "96          must       96\n",
       "97          laws       97\n",
       "98          book       98\n",
       "99   saudiarabia       99\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM \" + db + \".vocab\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status_id=u'972175221481459712', text=u'When your wonderful friend is on a trip around the world to literally help save the planet and you\\u2018re at home watching cat videos all day... \\U0001f602 #goSarah! @GreenpeaceAT @SarahSchrf https://t.co/h3CZbdEO5R', words=[u'when', u'your', u'wonderful', u'friend', u'trip', u'around', u'world', u'literally', u'help', u'save', u'planet', u'home', u'watching', u'videos', u'gosarah', u'greenpeaceat', u'sarahschrf', u'https', u'h3czbdeo5r'], filtered=[u'wonderful', u'friend', u'trip', u'around', u'world', u'literally', u'help', u'save', u'planet', u'home', u'watching', u'videos', u'gosarah', u'greenpeaceat', u'sarahschrf', u'https', u'h3czbdeo5r'], features=SparseVector(100, {0: 1.0, 19: 1.0, 49: 1.0})),\n",
       " Row(status_id=u'972082111606939648', text=u'@GrandHuit Rettet die Pinguine! #SaveAntarctic https://t.co/p7Dk438z3R', words=[u'grandhuit', u'rettet', u'pinguine', u'saveantarctic', u'https', u'p7dk438z3r'], filtered=[u'grandhuit', u'rettet', u'pinguine', u'saveantarctic', u'https', u'p7dk438z3r'], features=SparseVector(100, {0: 1.0})),\n",
       " Row(status_id=u'973220871551807490', text=u'\"The melon patent provides evidence that the EPO is continuing to grant patents on plants and animals derived from conventional breeding\" https://t.co/MNqUDvf55B - @NoPatentsOnSeed @arche__noah', words=[u'melon', u'patent', u'provides', u'evidence', u'that', u'continuing', u'grant', u'patents', u'plants', u'animals', u'derived', u'from', u'conventional', u'breeding', u'https', u'mnqudvf55b', u'nopatentsonseed', u'arche__noah'], filtered=[u'melon', u'patent', u'provides', u'evidence', u'continuing', u'grant', u'patents', u'plants', u'animals', u'derived', u'conventional', u'breeding', u'https', u'mnqudvf55b', u'nopatentsonseed', u'arche__noah'], features=SparseVector(100, {0: 1.0}))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cvmodel.transform(filtered_words_sdf)\n",
    "result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.saveAsTable(db + \".words\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark2",
   "language": "python",
   "name": "anaconda-pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

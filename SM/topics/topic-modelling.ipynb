{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load libraries, declaration of global variables\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import DataFrameWriter\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "import pandas as pd\n",
    "\n",
    "db = \"sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load chosen data into a spark data frame\n",
    "df = spark.sql(\"SELECT status_id, translatedText AS text FROM \" + db + \".twitter_translations\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize text\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\", minTokenLength=4, \n",
    "                                toLowercase=True)\n",
    "df = regexTokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop a standard list of words\n",
    "stopwordList = [\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\n",
    "                \"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\n",
    "                \"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\n",
    "                \"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\n",
    "                \"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\n",
    "                \"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\n",
    "                \"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\n",
    "                \"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\n",
    "                \"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\",\"like\",\"would\",\"find\",\"part\",\"href\", \"bock\", \"poland\",\n",
    "                \"people\"]\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=stopwordList)\n",
    "df = remover.transform(df)\n",
    "df = df.filter(\"text <> ''\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute counts of words in tweets/comments\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5.0)\n",
    "model = cv.fit(df)\n",
    "vocabulary_local = pd.DataFrame(model.vocabulary, columns = [\"word\"])\n",
    "vocabulary_local.head()\n",
    "# model.transform(df).show()\n",
    "df = model.transform(df)\n",
    "df=df.drop('text', 'words','filtered')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discovering topics through LDA algorithm\n",
    "# seed not working??? different results even though the seed is set...\n",
    "num_topics = 7 #,maxIter=10\n",
    "lda = LDA(k=num_topics, seed=1, optimizer=\"em\")\n",
    "model = lda.fit(df)\n",
    "modelres = model.transform(df)\n",
    "model.describeTopics().show()\n",
    "modelres.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA results\n",
    "pd_topics = model.describeTopics().toPandas()\n",
    "pd_topics.head()\n",
    "df_terms = vocabulary_local.reset_index()\n",
    "translate = df_terms.set_index('index').to_dict()['word']\n",
    "empty_list = [[] for x in range(len(pd_topics))]\n",
    "for i in range(len(pd_topics)):\n",
    "    for j in range(0,len(pd_topics['termIndices'][i])):\n",
    "        empty_list[i].append(translate[pd_topics['termIndices'][i][j]])\n",
    "pd_topics_bu = pd_topics\n",
    "pd_topics_bu['termIndices'] = empty_list\n",
    "pd_topics_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top ten influential words for each topic\n",
    "for i in range(0,num_topics):\n",
    "    print(pd_topics_bu['termIndices'][i])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re-score data (assign the topic with the highest probability to each tweet/comment)\n",
    "modelres = model.transform(df)\n",
    "modelres = modelres.toPandas()\n",
    "modelres.head()\n",
    "max_index=[]\n",
    "for i in modelres['topicDistribution']:\n",
    "    i=i.tolist()\n",
    "    max_value = max(i)\n",
    "    max_index.append(i.index(max_value))\n",
    "modelres['topicindex'] = max_index\n",
    "topicname = {0:'poland_anti_ukraine',1:'forrest_needs',2:'polish_government_support',3:'poland_jews',4:'forrest_support'}\n",
    "modelres['topicindex'].replace(topicname,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine data with sentiment data\n",
    "df_sentiments = spark.sql(\"SELECT * FROM sm.twitter_sentiment_fb\").toPandas()\n",
    "trada=modelres.merge(df_sentiments,how='inner',on='status_id')\n",
    "trada.groupby(\"topicindex\")['love','angry','haha','wow','sad'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
